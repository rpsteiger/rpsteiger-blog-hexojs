{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1599213951604},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1599213955808},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1599213955808},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1599213955808},{"_id":"themes/landscape/README.md","hash":"37fae88639ef60d63bd0de22314d7cc4c5d94b07","modified":1599213955808},{"_id":"themes/landscape/_config.yml","hash":"79ac6b9ed6a4de5a21ea53fc3f5a3de92e2475ff","modified":1599213955808},{"_id":"themes/landscape/package.json","hash":"544f21a0b2c7034998b36ae94dba6e3e0f39f228","modified":1599213955815},{"_id":"themes/landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1599213955809},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1599213955809},{"_id":"themes/landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1599213955809},{"_id":"themes/landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1599213955809},{"_id":"themes/landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1599213955809},{"_id":"themes/landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1599213955809},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1599213955810},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1599213955810},{"_id":"themes/landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1599213955810},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1599213955810},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1599213955810},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1599213955811},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1599213955815},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1599213955815},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1599213955815},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1599213955815},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1599213955815},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1599213955815},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1599213955815},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1599213955816},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"d0d753d39038284d52b10e5075979cc97db9cd20","modified":1599213955811},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1599213955811},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"950ddd91db8718153b329b96dc14439ab8463ba5","modified":1599213955811},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/gauges-analytics.ejs","hash":"aad6312ac197d6c5aaf2104ac863d7eba46b772a","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"5abf77aec957d9445fc71a8310252f0013c84578","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"7e749050be126eadbc42decfbea75124ae430413","modified":1599213955812},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1599213955814},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1599213955814},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1599213955814},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1599213955814},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1599213955814},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1599213955814},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1599213955816},{"_id":"themes/landscape/source/css/_variables.styl","hash":"628e307579ea46b5928424313993f17b8d729e92","modified":1599213955817},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1599213955822},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1599213955822},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1599213955824},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1599213955824},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1599213955825},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1599213955825},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1599213955813},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1599213955813},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1599213955816},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1599213955816},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1599213955816},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1599213955816},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1599213955816},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1599213955817},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1599213955817},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1599213955817},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1599213955817},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1599213955817},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1599213955817},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1599213955817},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1599213955818},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1599213955818},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1599213955820},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1599213955823},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1599213955824},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1599213955824},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1599213955824},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1599213955824},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1599213955820},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1599213955819},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1599213955822},{"_id":"source/_posts/Hello-Hexo.md","hash":"643b1bf5583ab402c208e9aa0b1e4cac9b275302","modified":1599214271113},{"_id":"public/2020/09/04/Hello-Hexo/index.html","hash":"d69c7fe2bacb3276071b5e4cbf5dbc6035f3566f","modified":1599219938134},{"_id":"public/2020/09/04/hello-world/index.html","hash":"409bfe70b4030d50a59b8b087d82ede29a86213d","modified":1599219938134},{"_id":"public/archives/index.html","hash":"4635416139670183d470643a5404474cdaaaca94","modified":1599219938134},{"_id":"public/archives/2020/index.html","hash":"2cb80ac2f1bb0e48fcfe08d6f237b20c851a4cce","modified":1599219938134},{"_id":"public/archives/2020/09/index.html","hash":"6c9f4346699022a0cb1c408326e71f7d0e44dcc9","modified":1599219938134},{"_id":"public/index.html","hash":"727a08ffd598fc02fbe54628c28f89f5f4c6e880","modified":1599219938134},{"_id":"source/_posts/Summary-of-Dirk-Helbing-s-Whats-Wrong-with-AI.md","hash":"43ae99819592446ae3f92a18d964c73cc540092f","modified":1599429367303},{"_id":"source/_posts/part-two-thoughts-on-ai.md","hash":"180075f66f708d45cfdac4de7daf97792a9bba18","modified":1604430589573}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Summary of Dirk Helbing's 'Whats Wrong with AI?'","date":"2020-09-06T21:52:16.000Z","_content":"\n## AI on the Rise\nThe author delves into the topic by saying that AI is everywhere: automated driving (among other everyday appliations), digital assistants such as Siri, Alexa, Google Home are to be found more and more frequently.  \nThis is followed by an interesting prediction from Ray Kurzweil who predicted that AI would have the power of an insectoid brain in the year 2000; the cognitive capabilities of a mouse brain in year 2010; human-like brain cognition around the year 2020; and eventually the power of _all human_ brains in the middle of the century. Many think this merely techno-optimistic. This hyptothesis could be supported (or not) by successful AI projects such as the IBM Deep Blue computer, who beat chess genius Garry Kasparov in 1997, or Google's AlphaGo system which beat the reigning world champion Lee Sedol in the strategy game \"Go\" in 2016.  \nHere is another example from an old personal interest of mine: the real-time strategy (video) game Starcraft II. Many consider Starcraft a truly hard game among games. It is often said--in an impolite manner among players--that Starcraft is much more complex than your MOBA of choice (be it DOTA or League of Legends). Korean players have dominated the scene over years with their (almost) impeccable execution. It takes years too master Starcraft and many players dedicated years of their life to do so. Last year in 2019 ,as I am writing this, on December the 19th an AI called AlphaStar beat TLO's legend MaNa under tournament condition in best of five 5-0! The games were played under tournament condition (as known from the WCS). For further reading head to this very insightful article on deepmind.com: [AlphaStar: Mastering the Real-Time Strategy Game StarCraft II](https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii). I would like to add that the article did not mention whether AlphaStar was tested against Korean players. I would also like to know whether other matchups than PvP were played.\n\n## AI as God\nApparently former Google engineer Anthony Levandovski is dead-serious about starting a religion whose deity is an AI. Levandowski says the new religion, “Way of the Future,” will focus on “the realization, acceptance, and worship of a Godhead based on AI developed through computer hardware and software.”  \nThe article then mentions that we are (and have been for some years) heavily influenced by AI algorithms. The TED talk [How a handful of tech companies control billions of minds every day](https://www.youtube.com/watch?v=C74amJRp730) by Tristan Harris--another former Google employee who talks about people in a control room who literally control the way we think. This really got me to think on how heavily I am being manipulated--for I believe to know that I can be manipulated are probably are.\n\n## Singularity\nThe word singularity has multiple meanings. I think the following (from merriam webster) is the most fitting in this context: \n> a point at which the derivative of a given function of a complex variable does not exist but every neighborhood of which contains points for which the derivative does exist\n\nUnfortunately, I do not understand calculus with complex numbers. However, from what I understand this means that there exists a certain (complex) point on a graph to which no derivativ exists.  \nAccording to Wikipedia the term technical technology is (neatly) defined as follows: \n> the singularity is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization\n\nIn as early as the 1960s, computer scientists already conjectured about what they call intelligence explosion--the point where exponential growth supersedes human-like intelligence in a manner that can be considered the singularity. I. J. Good speculated: \n>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.\n\nThis took me back to Alan Turing's paper \"Computing Machinery and Intelligence\", which I had done a presention on for English class. My presentation mostly used the eccentricities of the paper and shocked people with the fact that Turing believed in the existence of telepathy and that his paper contained a discussion on religion--which I believe he took dead-serious, found in the section \"The Theological Objection\". Turing's thoughts on whether \"hard\"-AIs can be built can be found in the paper in the Section \"Learning Machines\". Plus, Turing went as far as to include his thoughts on how such a hypothecial machine might be trained. A very good read, especially, when one keeps in mind that Turing wrote this in 1950 when computers filled whole rooms!\n\nFurthermore, I learned from Wikipedia, that it was John von Neumann who came up with the word singluarity (in the technical context). Curious as I was I clicked on the the hyperlink to [Neumann's article](https://en.wikipedia.org/wiki/John_von_Neumann) to learn that he was a higly impressive Mathematician. I knew his name from the [von Neumann architecture](https://en.wikipedia.org/wiki/Von_Neumann_architecture) (a model for low-level CPU architecture). But this was, as I now understand, just one of his accomplishments. He is, among other things, the founder of Game Theory.\n\nThe article poses the question whether a singularity is likely and mentions some popular outcries for caution. Stephen Hawking with a evolutionary argument: \"Humans, who are limited by slow biological evolution, couldn't compete and would be superseded.\" and as I have read many times in everyday media Elon Musk has the following to say: \"We should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that.\" For more details on the latter one could listen the The Podcast Episode [Joe Rogan Experience #1470 - Elon Musk](https://www.youtube.com/watch?v=RcYjXbSJBN8), and not for the fact that Mr. Musk is smoking pot on \"air\", but for the relaxed discussion of AI.  \nTherefore, it is time to ask the question, what whill happen with humans and humanity after the singularity?, Dirk Helbing goes on. There are different views on the subject, one of them (Schmidhuber) claims that superintelligent robots will be as little interested in humans as we are in ants, but this does not imply that there would be no conflict for resources. Others fear for unenployment on a large scale. And then there is an optimistic viewpoint with the belief in an utopian world, the so called \"Second Machine Age\".\n\n## Transhumanism\nTaken from the article on [Transhumanism](https://en.wikipedia.org/wiki/Transhumanism) on Wikipedia:\n> Transhumanist thinkers study the potential benefits and dangers of emerging technologies that could overcome fundamental human limitations as well as the ethical limitations of using such technologies. The most common transhumanist thesis is that human beings may eventually be able to transform themselves into different beings with abilities so greatly expanded from the current condition as to merit the label of posthuman beings.\n\nThe article notes that not only is the future of humanity up for debate, but also human existence itself. Some, among those is Elon Musk, believe that humans will need augmentations to stay on level with AI and to eventually merge with it.\n\n## Is AI really intelligent?\nThis must be my favourite part of the paper. Here, Dr. Helbing shares his own views with us on the currently existing \"soft\"-AIs.  \nIn order to determine the true intelligence quality of AIs he considers whether they are autonomous, capable of emotion, capable of creativity, and conscious.  \nThis reminds me, yet again, to Turing's paper, who also tried to determine whether a computer could be capable of writing a sonnet. Dr. Helbing thinks that AI's are not autonomous, because they require human maintenance and external resources (also) provided by humans; thinks that AI systems are not capapble of emotion, due to the fact that mimicking emotion is not the same as actually feeling an emotion; and to the question whether he thinks that AI systems are conscious he answers simply: I would say \"no\", by argueing that we do not yet understand consciousness at all.  \nAt the end of this section the author notes that attemping to create humanoid robots might teach us a lesson or two about what love or consciousness is--then how are we supposed to create what we do not yet understand.  \nI will dare to add a personal note here. I do not yet understand the current neuroscience literature at all. In my bookshelf at home sits a book on consciousness and I haven't touched the bloody thing yet. I know about as much about love, but I liked Brené Brown's definition of it. In case you are interested in reading a definition of love, look on her website on [https://brenebrown.com/definitions/](https://brenebrown.com/definitions/).\n\n## What is consciousness\nThis part discusses the conjecture that world is an interpretation of higher-dimensional data. Furthermore the world was not limited to three dimension, but it is us who can only perceive it that way. Then as the author notes, the permanent distractions by the attention economy would just be the opposite of what would be needed to advance humanity.  \nTo make this more plausible the following example is given: consider why Egyptian and ancient paintings look flat, i.e. two-dimensional. Did ancient people see the world with _literally_ different eyes? This is interesting to think about, however I think it is too simplistic and narrow minded in it's analysis.\n\n## Big Data Analytics\nChris Anderson claimed in an article in \"Wired\" magazine in 2008 that the scientific method would soon be obsolete due to Big Data Analysis. Simplified, that if one had just enough data, data quntity could be turned into data quality and thus the truth would eventually reveal itself.  \nHowever, so far it seems to be harder than perhabs anticipated to harvest meaningful data. This seems to stem in part from false positives.\n\n## Correlation vs. Causality\nIn Big Data patterns and correlations are easily found. However, one can not make any conclusions from said correlations. The following example is given: consider the correlation between the number of ice-cream-eating children and the number of forest fires. Forbidding children to eat ice cream will obviously not reduce the number of forest fires at all--despite the strong correlation in the data. It is obviously a third factor that causes both increased ince cream consumption and forest fires!\n\n## Trustable AI\nIdeally we could use AI to make sense of Big Data for us. However, according to Dr. Helbing AI's can only do this partly due to the fact that they show bias against women, non-white people, or minorities--this happens because they are usually trained with data of the past. Additionally, an AI can not explain it's own action, which could lead to a sitation where e.g. your application for a loan or life insurance is turned down, but nobody can tell you why.\n\n## Profiling, Targeting, and Digital Twins\nThanks to the Edward Snowden leaks, we know that (at least) the American intelligence services have been running mass surveillance programs under the guise of fighting terrorism. Doing this, they created \"profiles\" of everyone. Dr. Elbing says \"You may imagine this like a black box that has been crated for everyone, which is continuously fed with surveillance data and learns to behave like the humans they are imitating.\" Such systems can be used to personalize information and finally manipulate our behaviour in the way (most desirable) to the highest bidder.  \nThis reminds me of the Cambridge Analytic facebook manipulation case that is well documented in the Netflix documentation [The Great Hack](https://www.netflix.com/Title/80117542).\n\n## Data Protection?\nThe EU General Data Protection Regulation (GDPR) should have protected us from mass surveillance, profiling and targeting in theory. But it did not, as the Snowden files showed. It seems almost impossible to use the internet without agreeing to Terms of Use beforehand, those contracts typically forces one into agreeing to the collection of ones personal data.  \nThe author additionally notes that we cannot even assume those personal profiles to be reliable (to be accurate). He notes the chances digital twins behave identical to us are not very high.\n\n## Scoring, Citizen Scores, Superscores\nScoring is simillar to building a profile for people based on their personal data; however, it also assigns a value to peoples attributes, and data that eventually leads to a numerical value the score. Said value heavily inflicts one's life as it determines products availabe for them or more generally how one is treated. China is currently testing this approach under the name \"Social Credit Score\". According to the author the program may be seen as an attempt to make citizens obedient to the government's wishes, which has been critized as data dictatorship or technological totalitarianism.\n\n## Automation vs. Freedom\nIn the age of AI it is tempting to automate processes of all kinds, including decision making. The latter often involes (either explicitly or implicitly) evaluating based on an index or a one-dimensional descision function. It is tempting to decide in a statistical manner. However the author heavily argues against this, for it effectively eliminates free choice. Alternatively, he proposes a semi-automated approach that reduces the decisions humans have to make by deciding the sure cases, while leaving the complex cases for the humans to process.\n\n## Learning to Die?\n\n\n## A revolution from above?\n\n## Human Rights\nAccording to the author human rights were established, due to the horrors of the twentiest century. He then goes on to say that the establishment of human rights is axiomatic for the foundation of modern civilizatin, which in turn is reflected by the UN's Universal Declaration of Human Rights--to prevent such catastrophies from happening again in the future.\n\nAs a student of Jordan Peterson and Alexandr Solzhenitsyn I could hardly disagree more. Firstly, I think it as wrong to proclaim that pre WW people had no human right. Can not the American constitution (as just one of many exmaples) be seen as proof for such a thing? Secondly, I believe that the burden to prevent a second 20th century is to solve at an individual level, and not by the UN or personal rights!  \nHowever, in the next sentence Dr. Helbing argues that the promoting of a materialistic consumption-driven society has led the the current (non-) sustainability crisis. With this I can partly agree.\n\nIn the last paragraph the author points out that we would be living in a self sustaining world had the industrialized countries managed to reduce their resource consumption by 3% annually since the 1970s. I don't really know what to make of this, since I don't know any of the related literature.\n\n## Happiness vs. Capitalism\nDr. Helbing argues that autonomy and good relationships are the best indicators for promoting personal happiness. He then goes saying, \"I believe, if our soceity would be designed and managed in a way that supports the happiness of people, it would also be more sustainable, because happy people do not consume that much.\" I do not agree with this hypothesis or believe it at least to be overly simplistic. How can we know that happy people consume less?\n\nHowever in the next paragraph the author points out that tech companies are partly to blame for the problems we are facing today. By their utilitarian practice of making users pay with their personal data and then selling that data to other companies, they might be seriously violating what we perceive as our right to privacy.\n\n## Human Dignity\nAccording to Dr. Helbing human dignity is given to us at birth and is axiomatic to societal values. The right to be treated as human towers above everything else. Politics and other institutions must do what they can, in order to proect human dignity from violations by public institutions etc. By not engaging in this practice public institutions lose their legitimacy.\n\nBut what is human dignity? The author says that it means to be treated differently from objects and animals, but as human--this is yet again (also) mentioned in Turing's paper on AI, where he explains that animals do not possess a soul in Christianity. It means to have the right to be involved in decisions and affaris that concern them, including the right of informational self-determination. Exposing people to unwanted mass surveillance is a clear violation of that.  \nAt the end of the section Dr. Helbing proclaims: \"I do, therefore, urge public and private actors to push informational self-determination forward quickly.\"\n\n## Informational Self-Determination\nI had to look up what is meant with informational self-determination. According to the Wikipedia article it is derived from the German word \"informationelle Selbstbestimmung\" and stands for the right for one to decide for himself what of his data should be communicated with others and what should be kept private.\n\nDr. Helbing proposes a platform that would allow individuals to control which private data they allow a service to collect--and therefore allow them to use for e.g. personalized content, for which period of time, and perhabs for whichprice. The resulting competition for consumer trust could eventually promote a trustable digital society.\n\nAccording to the author this platform would create a level playing field, for not only big businesses but also small organizations could work with the data (access approved by the people).\n\nIn Dr. Helbing's own words in the last paragraph in this section: \"Over time, if implemented well, such an approach would establish a thriving trustable digital age that empowers people, companies and governments alike, while making quick progress towards a sustainable and peaceful world.\n\n## Design for Values\n\n## Democracy by Design\nThe author notes that among the social engineers of the digital age democracy has often been framed as outdated technology. \n\nThe author then names \"human dignity and human rights, (informational) self-determination, freedom (combined with accountability), pluralism, protection of minorities, division of power, checks and balances, participation, transparency, fairness, justice, legitimacy, anonymous and equal votes, and privacy\" as relevant values for democracy.\n\n## Fairness\nThe final topic on this paper is a discussion of the power of fairness: whether it is a good idea that everyone has a single vote. Contrary to European democratic values, shouldn't smart people have more than one vote? According to the author experimental evidence about the \"wisdom of crowds\" surprisingly suggests, giving people different weights does not improve results. \"On the contrary, studies in collective intelligence show that largely unequal influence on a debate will reduce social intelligence\", Dr. Helbing points out.","source":"_posts/Summary-of-Dirk-Helbing-s-Whats-Wrong-with-AI.md","raw":"---\ntitle: Summary of Dirk Helbing's 'Whats Wrong with AI?'\ndate: 2020-09-06 23:52:16\ntags:\n---\n\n## AI on the Rise\nThe author delves into the topic by saying that AI is everywhere: automated driving (among other everyday appliations), digital assistants such as Siri, Alexa, Google Home are to be found more and more frequently.  \nThis is followed by an interesting prediction from Ray Kurzweil who predicted that AI would have the power of an insectoid brain in the year 2000; the cognitive capabilities of a mouse brain in year 2010; human-like brain cognition around the year 2020; and eventually the power of _all human_ brains in the middle of the century. Many think this merely techno-optimistic. This hyptothesis could be supported (or not) by successful AI projects such as the IBM Deep Blue computer, who beat chess genius Garry Kasparov in 1997, or Google's AlphaGo system which beat the reigning world champion Lee Sedol in the strategy game \"Go\" in 2016.  \nHere is another example from an old personal interest of mine: the real-time strategy (video) game Starcraft II. Many consider Starcraft a truly hard game among games. It is often said--in an impolite manner among players--that Starcraft is much more complex than your MOBA of choice (be it DOTA or League of Legends). Korean players have dominated the scene over years with their (almost) impeccable execution. It takes years too master Starcraft and many players dedicated years of their life to do so. Last year in 2019 ,as I am writing this, on December the 19th an AI called AlphaStar beat TLO's legend MaNa under tournament condition in best of five 5-0! The games were played under tournament condition (as known from the WCS). For further reading head to this very insightful article on deepmind.com: [AlphaStar: Mastering the Real-Time Strategy Game StarCraft II](https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii). I would like to add that the article did not mention whether AlphaStar was tested against Korean players. I would also like to know whether other matchups than PvP were played.\n\n## AI as God\nApparently former Google engineer Anthony Levandovski is dead-serious about starting a religion whose deity is an AI. Levandowski says the new religion, “Way of the Future,” will focus on “the realization, acceptance, and worship of a Godhead based on AI developed through computer hardware and software.”  \nThe article then mentions that we are (and have been for some years) heavily influenced by AI algorithms. The TED talk [How a handful of tech companies control billions of minds every day](https://www.youtube.com/watch?v=C74amJRp730) by Tristan Harris--another former Google employee who talks about people in a control room who literally control the way we think. This really got me to think on how heavily I am being manipulated--for I believe to know that I can be manipulated are probably are.\n\n## Singularity\nThe word singularity has multiple meanings. I think the following (from merriam webster) is the most fitting in this context: \n> a point at which the derivative of a given function of a complex variable does not exist but every neighborhood of which contains points for which the derivative does exist\n\nUnfortunately, I do not understand calculus with complex numbers. However, from what I understand this means that there exists a certain (complex) point on a graph to which no derivativ exists.  \nAccording to Wikipedia the term technical technology is (neatly) defined as follows: \n> the singularity is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization\n\nIn as early as the 1960s, computer scientists already conjectured about what they call intelligence explosion--the point where exponential growth supersedes human-like intelligence in a manner that can be considered the singularity. I. J. Good speculated: \n>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.\n\nThis took me back to Alan Turing's paper \"Computing Machinery and Intelligence\", which I had done a presention on for English class. My presentation mostly used the eccentricities of the paper and shocked people with the fact that Turing believed in the existence of telepathy and that his paper contained a discussion on religion--which I believe he took dead-serious, found in the section \"The Theological Objection\". Turing's thoughts on whether \"hard\"-AIs can be built can be found in the paper in the Section \"Learning Machines\". Plus, Turing went as far as to include his thoughts on how such a hypothecial machine might be trained. A very good read, especially, when one keeps in mind that Turing wrote this in 1950 when computers filled whole rooms!\n\nFurthermore, I learned from Wikipedia, that it was John von Neumann who came up with the word singluarity (in the technical context). Curious as I was I clicked on the the hyperlink to [Neumann's article](https://en.wikipedia.org/wiki/John_von_Neumann) to learn that he was a higly impressive Mathematician. I knew his name from the [von Neumann architecture](https://en.wikipedia.org/wiki/Von_Neumann_architecture) (a model for low-level CPU architecture). But this was, as I now understand, just one of his accomplishments. He is, among other things, the founder of Game Theory.\n\nThe article poses the question whether a singularity is likely and mentions some popular outcries for caution. Stephen Hawking with a evolutionary argument: \"Humans, who are limited by slow biological evolution, couldn't compete and would be superseded.\" and as I have read many times in everyday media Elon Musk has the following to say: \"We should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that.\" For more details on the latter one could listen the The Podcast Episode [Joe Rogan Experience #1470 - Elon Musk](https://www.youtube.com/watch?v=RcYjXbSJBN8), and not for the fact that Mr. Musk is smoking pot on \"air\", but for the relaxed discussion of AI.  \nTherefore, it is time to ask the question, what whill happen with humans and humanity after the singularity?, Dirk Helbing goes on. There are different views on the subject, one of them (Schmidhuber) claims that superintelligent robots will be as little interested in humans as we are in ants, but this does not imply that there would be no conflict for resources. Others fear for unenployment on a large scale. And then there is an optimistic viewpoint with the belief in an utopian world, the so called \"Second Machine Age\".\n\n## Transhumanism\nTaken from the article on [Transhumanism](https://en.wikipedia.org/wiki/Transhumanism) on Wikipedia:\n> Transhumanist thinkers study the potential benefits and dangers of emerging technologies that could overcome fundamental human limitations as well as the ethical limitations of using such technologies. The most common transhumanist thesis is that human beings may eventually be able to transform themselves into different beings with abilities so greatly expanded from the current condition as to merit the label of posthuman beings.\n\nThe article notes that not only is the future of humanity up for debate, but also human existence itself. Some, among those is Elon Musk, believe that humans will need augmentations to stay on level with AI and to eventually merge with it.\n\n## Is AI really intelligent?\nThis must be my favourite part of the paper. Here, Dr. Helbing shares his own views with us on the currently existing \"soft\"-AIs.  \nIn order to determine the true intelligence quality of AIs he considers whether they are autonomous, capable of emotion, capable of creativity, and conscious.  \nThis reminds me, yet again, to Turing's paper, who also tried to determine whether a computer could be capable of writing a sonnet. Dr. Helbing thinks that AI's are not autonomous, because they require human maintenance and external resources (also) provided by humans; thinks that AI systems are not capapble of emotion, due to the fact that mimicking emotion is not the same as actually feeling an emotion; and to the question whether he thinks that AI systems are conscious he answers simply: I would say \"no\", by argueing that we do not yet understand consciousness at all.  \nAt the end of this section the author notes that attemping to create humanoid robots might teach us a lesson or two about what love or consciousness is--then how are we supposed to create what we do not yet understand.  \nI will dare to add a personal note here. I do not yet understand the current neuroscience literature at all. In my bookshelf at home sits a book on consciousness and I haven't touched the bloody thing yet. I know about as much about love, but I liked Brené Brown's definition of it. In case you are interested in reading a definition of love, look on her website on [https://brenebrown.com/definitions/](https://brenebrown.com/definitions/).\n\n## What is consciousness\nThis part discusses the conjecture that world is an interpretation of higher-dimensional data. Furthermore the world was not limited to three dimension, but it is us who can only perceive it that way. Then as the author notes, the permanent distractions by the attention economy would just be the opposite of what would be needed to advance humanity.  \nTo make this more plausible the following example is given: consider why Egyptian and ancient paintings look flat, i.e. two-dimensional. Did ancient people see the world with _literally_ different eyes? This is interesting to think about, however I think it is too simplistic and narrow minded in it's analysis.\n\n## Big Data Analytics\nChris Anderson claimed in an article in \"Wired\" magazine in 2008 that the scientific method would soon be obsolete due to Big Data Analysis. Simplified, that if one had just enough data, data quntity could be turned into data quality and thus the truth would eventually reveal itself.  \nHowever, so far it seems to be harder than perhabs anticipated to harvest meaningful data. This seems to stem in part from false positives.\n\n## Correlation vs. Causality\nIn Big Data patterns and correlations are easily found. However, one can not make any conclusions from said correlations. The following example is given: consider the correlation between the number of ice-cream-eating children and the number of forest fires. Forbidding children to eat ice cream will obviously not reduce the number of forest fires at all--despite the strong correlation in the data. It is obviously a third factor that causes both increased ince cream consumption and forest fires!\n\n## Trustable AI\nIdeally we could use AI to make sense of Big Data for us. However, according to Dr. Helbing AI's can only do this partly due to the fact that they show bias against women, non-white people, or minorities--this happens because they are usually trained with data of the past. Additionally, an AI can not explain it's own action, which could lead to a sitation where e.g. your application for a loan or life insurance is turned down, but nobody can tell you why.\n\n## Profiling, Targeting, and Digital Twins\nThanks to the Edward Snowden leaks, we know that (at least) the American intelligence services have been running mass surveillance programs under the guise of fighting terrorism. Doing this, they created \"profiles\" of everyone. Dr. Elbing says \"You may imagine this like a black box that has been crated for everyone, which is continuously fed with surveillance data and learns to behave like the humans they are imitating.\" Such systems can be used to personalize information and finally manipulate our behaviour in the way (most desirable) to the highest bidder.  \nThis reminds me of the Cambridge Analytic facebook manipulation case that is well documented in the Netflix documentation [The Great Hack](https://www.netflix.com/Title/80117542).\n\n## Data Protection?\nThe EU General Data Protection Regulation (GDPR) should have protected us from mass surveillance, profiling and targeting in theory. But it did not, as the Snowden files showed. It seems almost impossible to use the internet without agreeing to Terms of Use beforehand, those contracts typically forces one into agreeing to the collection of ones personal data.  \nThe author additionally notes that we cannot even assume those personal profiles to be reliable (to be accurate). He notes the chances digital twins behave identical to us are not very high.\n\n## Scoring, Citizen Scores, Superscores\nScoring is simillar to building a profile for people based on their personal data; however, it also assigns a value to peoples attributes, and data that eventually leads to a numerical value the score. Said value heavily inflicts one's life as it determines products availabe for them or more generally how one is treated. China is currently testing this approach under the name \"Social Credit Score\". According to the author the program may be seen as an attempt to make citizens obedient to the government's wishes, which has been critized as data dictatorship or technological totalitarianism.\n\n## Automation vs. Freedom\nIn the age of AI it is tempting to automate processes of all kinds, including decision making. The latter often involes (either explicitly or implicitly) evaluating based on an index or a one-dimensional descision function. It is tempting to decide in a statistical manner. However the author heavily argues against this, for it effectively eliminates free choice. Alternatively, he proposes a semi-automated approach that reduces the decisions humans have to make by deciding the sure cases, while leaving the complex cases for the humans to process.\n\n## Learning to Die?\n\n\n## A revolution from above?\n\n## Human Rights\nAccording to the author human rights were established, due to the horrors of the twentiest century. He then goes on to say that the establishment of human rights is axiomatic for the foundation of modern civilizatin, which in turn is reflected by the UN's Universal Declaration of Human Rights--to prevent such catastrophies from happening again in the future.\n\nAs a student of Jordan Peterson and Alexandr Solzhenitsyn I could hardly disagree more. Firstly, I think it as wrong to proclaim that pre WW people had no human right. Can not the American constitution (as just one of many exmaples) be seen as proof for such a thing? Secondly, I believe that the burden to prevent a second 20th century is to solve at an individual level, and not by the UN or personal rights!  \nHowever, in the next sentence Dr. Helbing argues that the promoting of a materialistic consumption-driven society has led the the current (non-) sustainability crisis. With this I can partly agree.\n\nIn the last paragraph the author points out that we would be living in a self sustaining world had the industrialized countries managed to reduce their resource consumption by 3% annually since the 1970s. I don't really know what to make of this, since I don't know any of the related literature.\n\n## Happiness vs. Capitalism\nDr. Helbing argues that autonomy and good relationships are the best indicators for promoting personal happiness. He then goes saying, \"I believe, if our soceity would be designed and managed in a way that supports the happiness of people, it would also be more sustainable, because happy people do not consume that much.\" I do not agree with this hypothesis or believe it at least to be overly simplistic. How can we know that happy people consume less?\n\nHowever in the next paragraph the author points out that tech companies are partly to blame for the problems we are facing today. By their utilitarian practice of making users pay with their personal data and then selling that data to other companies, they might be seriously violating what we perceive as our right to privacy.\n\n## Human Dignity\nAccording to Dr. Helbing human dignity is given to us at birth and is axiomatic to societal values. The right to be treated as human towers above everything else. Politics and other institutions must do what they can, in order to proect human dignity from violations by public institutions etc. By not engaging in this practice public institutions lose their legitimacy.\n\nBut what is human dignity? The author says that it means to be treated differently from objects and animals, but as human--this is yet again (also) mentioned in Turing's paper on AI, where he explains that animals do not possess a soul in Christianity. It means to have the right to be involved in decisions and affaris that concern them, including the right of informational self-determination. Exposing people to unwanted mass surveillance is a clear violation of that.  \nAt the end of the section Dr. Helbing proclaims: \"I do, therefore, urge public and private actors to push informational self-determination forward quickly.\"\n\n## Informational Self-Determination\nI had to look up what is meant with informational self-determination. According to the Wikipedia article it is derived from the German word \"informationelle Selbstbestimmung\" and stands for the right for one to decide for himself what of his data should be communicated with others and what should be kept private.\n\nDr. Helbing proposes a platform that would allow individuals to control which private data they allow a service to collect--and therefore allow them to use for e.g. personalized content, for which period of time, and perhabs for whichprice. The resulting competition for consumer trust could eventually promote a trustable digital society.\n\nAccording to the author this platform would create a level playing field, for not only big businesses but also small organizations could work with the data (access approved by the people).\n\nIn Dr. Helbing's own words in the last paragraph in this section: \"Over time, if implemented well, such an approach would establish a thriving trustable digital age that empowers people, companies and governments alike, while making quick progress towards a sustainable and peaceful world.\n\n## Design for Values\n\n## Democracy by Design\nThe author notes that among the social engineers of the digital age democracy has often been framed as outdated technology. \n\nThe author then names \"human dignity and human rights, (informational) self-determination, freedom (combined with accountability), pluralism, protection of minorities, division of power, checks and balances, participation, transparency, fairness, justice, legitimacy, anonymous and equal votes, and privacy\" as relevant values for democracy.\n\n## Fairness\nThe final topic on this paper is a discussion of the power of fairness: whether it is a good idea that everyone has a single vote. Contrary to European democratic values, shouldn't smart people have more than one vote? According to the author experimental evidence about the \"wisdom of crowds\" surprisingly suggests, giving people different weights does not improve results. \"On the contrary, studies in collective intelligence show that largely unequal influence on a debate will reduce social intelligence\", Dr. Helbing points out.","slug":"Summary-of-Dirk-Helbing-s-Whats-Wrong-with-AI","published":1,"updated":"2020-09-06T21:56:07.303Z","_id":"ckermv5vi0000jxl37c5fe8i1","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"AI-on-the-Rise\"><a href=\"#AI-on-the-Rise\" class=\"headerlink\" title=\"AI on the Rise\"></a>AI on the Rise</h2><p>The author delves into the topic by saying that AI is everywhere: automated driving (among other everyday appliations), digital assistants such as Siri, Alexa, Google Home are to be found more and more frequently.<br>This is followed by an interesting prediction from Ray Kurzweil who predicted that AI would have the power of an insectoid brain in the year 2000; the cognitive capabilities of a mouse brain in year 2010; human-like brain cognition around the year 2020; and eventually the power of <em>all human</em> brains in the middle of the century. Many think this merely techno-optimistic. This hyptothesis could be supported (or not) by successful AI projects such as the IBM Deep Blue computer, who beat chess genius Garry Kasparov in 1997, or Google’s AlphaGo system which beat the reigning world champion Lee Sedol in the strategy game “Go” in 2016.<br>Here is another example from an old personal interest of mine: the real-time strategy (video) game Starcraft II. Many consider Starcraft a truly hard game among games. It is often said–in an impolite manner among players–that Starcraft is much more complex than your MOBA of choice (be it DOTA or League of Legends). Korean players have dominated the scene over years with their (almost) impeccable execution. It takes years too master Starcraft and many players dedicated years of their life to do so. Last year in 2019 ,as I am writing this, on December the 19th an AI called AlphaStar beat TLO’s legend MaNa under tournament condition in best of five 5-0! The games were played under tournament condition (as known from the WCS). For further reading head to this very insightful article on deepmind.com: <a href=\"https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii\">AlphaStar: Mastering the Real-Time Strategy Game StarCraft II</a>. I would like to add that the article did not mention whether AlphaStar was tested against Korean players. I would also like to know whether other matchups than PvP were played.</p>\n<h2 id=\"AI-as-God\"><a href=\"#AI-as-God\" class=\"headerlink\" title=\"AI as God\"></a>AI as God</h2><p>Apparently former Google engineer Anthony Levandovski is dead-serious about starting a religion whose deity is an AI. Levandowski says the new religion, “Way of the Future,” will focus on “the realization, acceptance, and worship of a Godhead based on AI developed through computer hardware and software.”<br>The article then mentions that we are (and have been for some years) heavily influenced by AI algorithms. The TED talk <a href=\"https://www.youtube.com/watch?v=C74amJRp730\">How a handful of tech companies control billions of minds every day</a> by Tristan Harris–another former Google employee who talks about people in a control room who literally control the way we think. This really got me to think on how heavily I am being manipulated–for I believe to know that I can be manipulated are probably are.</p>\n<h2 id=\"Singularity\"><a href=\"#Singularity\" class=\"headerlink\" title=\"Singularity\"></a>Singularity</h2><p>The word singularity has multiple meanings. I think the following (from merriam webster) is the most fitting in this context: </p>\n<blockquote>\n<p>a point at which the derivative of a given function of a complex variable does not exist but every neighborhood of which contains points for which the derivative does exist</p>\n</blockquote>\n<p>Unfortunately, I do not understand calculus with complex numbers. However, from what I understand this means that there exists a certain (complex) point on a graph to which no derivativ exists.<br>According to Wikipedia the term technical technology is (neatly) defined as follows: </p>\n<blockquote>\n<p>the singularity is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization</p>\n</blockquote>\n<p>In as early as the 1960s, computer scientists already conjectured about what they call intelligence explosion–the point where exponential growth supersedes human-like intelligence in a manner that can be considered the singularity. I. J. Good speculated: </p>\n<blockquote>\n<p>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.</p>\n</blockquote>\n<p>This took me back to Alan Turing’s paper “Computing Machinery and Intelligence”, which I had done a presention on for English class. My presentation mostly used the eccentricities of the paper and shocked people with the fact that Turing believed in the existence of telepathy and that his paper contained a discussion on religion–which I believe he took dead-serious, found in the section “The Theological Objection”. Turing’s thoughts on whether “hard”-AIs can be built can be found in the paper in the Section “Learning Machines”. Plus, Turing went as far as to include his thoughts on how such a hypothecial machine might be trained. A very good read, especially, when one keeps in mind that Turing wrote this in 1950 when computers filled whole rooms!</p>\n<p>Furthermore, I learned from Wikipedia, that it was John von Neumann who came up with the word singluarity (in the technical context). Curious as I was I clicked on the the hyperlink to <a href=\"https://en.wikipedia.org/wiki/John_von_Neumann\">Neumann’s article</a> to learn that he was a higly impressive Mathematician. I knew his name from the <a href=\"https://en.wikipedia.org/wiki/Von_Neumann_architecture\">von Neumann architecture</a> (a model for low-level CPU architecture). But this was, as I now understand, just one of his accomplishments. He is, among other things, the founder of Game Theory.</p>\n<p>The article poses the question whether a singularity is likely and mentions some popular outcries for caution. Stephen Hawking with a evolutionary argument: “Humans, who are limited by slow biological evolution, couldn’t compete and would be superseded.” and as I have read many times in everyday media Elon Musk has the following to say: “We should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it’s probably that.” For more details on the latter one could listen the The Podcast Episode <a href=\"https://www.youtube.com/watch?v=RcYjXbSJBN8\">Joe Rogan Experience #1470 - Elon Musk</a>, and not for the fact that Mr. Musk is smoking pot on “air”, but for the relaxed discussion of AI.<br>Therefore, it is time to ask the question, what whill happen with humans and humanity after the singularity?, Dirk Helbing goes on. There are different views on the subject, one of them (Schmidhuber) claims that superintelligent robots will be as little interested in humans as we are in ants, but this does not imply that there would be no conflict for resources. Others fear for unenployment on a large scale. And then there is an optimistic viewpoint with the belief in an utopian world, the so called “Second Machine Age”.</p>\n<h2 id=\"Transhumanism\"><a href=\"#Transhumanism\" class=\"headerlink\" title=\"Transhumanism\"></a>Transhumanism</h2><p>Taken from the article on <a href=\"https://en.wikipedia.org/wiki/Transhumanism\">Transhumanism</a> on Wikipedia:</p>\n<blockquote>\n<p>Transhumanist thinkers study the potential benefits and dangers of emerging technologies that could overcome fundamental human limitations as well as the ethical limitations of using such technologies. The most common transhumanist thesis is that human beings may eventually be able to transform themselves into different beings with abilities so greatly expanded from the current condition as to merit the label of posthuman beings.</p>\n</blockquote>\n<p>The article notes that not only is the future of humanity up for debate, but also human existence itself. Some, among those is Elon Musk, believe that humans will need augmentations to stay on level with AI and to eventually merge with it.</p>\n<h2 id=\"Is-AI-really-intelligent\"><a href=\"#Is-AI-really-intelligent\" class=\"headerlink\" title=\"Is AI really intelligent?\"></a>Is AI really intelligent?</h2><p>This must be my favourite part of the paper. Here, Dr. Helbing shares his own views with us on the currently existing “soft”-AIs.<br>In order to determine the true intelligence quality of AIs he considers whether they are autonomous, capable of emotion, capable of creativity, and conscious.<br>This reminds me, yet again, to Turing’s paper, who also tried to determine whether a computer could be capable of writing a sonnet. Dr. Helbing thinks that AI’s are not autonomous, because they require human maintenance and external resources (also) provided by humans; thinks that AI systems are not capapble of emotion, due to the fact that mimicking emotion is not the same as actually feeling an emotion; and to the question whether he thinks that AI systems are conscious he answers simply: I would say “no”, by argueing that we do not yet understand consciousness at all.<br>At the end of this section the author notes that attemping to create humanoid robots might teach us a lesson or two about what love or consciousness is–then how are we supposed to create what we do not yet understand.<br>I will dare to add a personal note here. I do not yet understand the current neuroscience literature at all. In my bookshelf at home sits a book on consciousness and I haven’t touched the bloody thing yet. I know about as much about love, but I liked Brené Brown’s definition of it. In case you are interested in reading a definition of love, look on her website on <a href=\"https://brenebrown.com/definitions/\">https://brenebrown.com/definitions/</a>.</p>\n<h2 id=\"What-is-consciousness\"><a href=\"#What-is-consciousness\" class=\"headerlink\" title=\"What is consciousness\"></a>What is consciousness</h2><p>This part discusses the conjecture that world is an interpretation of higher-dimensional data. Furthermore the world was not limited to three dimension, but it is us who can only perceive it that way. Then as the author notes, the permanent distractions by the attention economy would just be the opposite of what would be needed to advance humanity.<br>To make this more plausible the following example is given: consider why Egyptian and ancient paintings look flat, i.e. two-dimensional. Did ancient people see the world with <em>literally</em> different eyes? This is interesting to think about, however I think it is too simplistic and narrow minded in it’s analysis.</p>\n<h2 id=\"Big-Data-Analytics\"><a href=\"#Big-Data-Analytics\" class=\"headerlink\" title=\"Big Data Analytics\"></a>Big Data Analytics</h2><p>Chris Anderson claimed in an article in “Wired” magazine in 2008 that the scientific method would soon be obsolete due to Big Data Analysis. Simplified, that if one had just enough data, data quntity could be turned into data quality and thus the truth would eventually reveal itself.<br>However, so far it seems to be harder than perhabs anticipated to harvest meaningful data. This seems to stem in part from false positives.</p>\n<h2 id=\"Correlation-vs-Causality\"><a href=\"#Correlation-vs-Causality\" class=\"headerlink\" title=\"Correlation vs. Causality\"></a>Correlation vs. Causality</h2><p>In Big Data patterns and correlations are easily found. However, one can not make any conclusions from said correlations. The following example is given: consider the correlation between the number of ice-cream-eating children and the number of forest fires. Forbidding children to eat ice cream will obviously not reduce the number of forest fires at all–despite the strong correlation in the data. It is obviously a third factor that causes both increased ince cream consumption and forest fires!</p>\n<h2 id=\"Trustable-AI\"><a href=\"#Trustable-AI\" class=\"headerlink\" title=\"Trustable AI\"></a>Trustable AI</h2><p>Ideally we could use AI to make sense of Big Data for us. However, according to Dr. Helbing AI’s can only do this partly due to the fact that they show bias against women, non-white people, or minorities–this happens because they are usually trained with data of the past. Additionally, an AI can not explain it’s own action, which could lead to a sitation where e.g. your application for a loan or life insurance is turned down, but nobody can tell you why.</p>\n<h2 id=\"Profiling-Targeting-and-Digital-Twins\"><a href=\"#Profiling-Targeting-and-Digital-Twins\" class=\"headerlink\" title=\"Profiling, Targeting, and Digital Twins\"></a>Profiling, Targeting, and Digital Twins</h2><p>Thanks to the Edward Snowden leaks, we know that (at least) the American intelligence services have been running mass surveillance programs under the guise of fighting terrorism. Doing this, they created “profiles” of everyone. Dr. Elbing says “You may imagine this like a black box that has been crated for everyone, which is continuously fed with surveillance data and learns to behave like the humans they are imitating.” Such systems can be used to personalize information and finally manipulate our behaviour in the way (most desirable) to the highest bidder.<br>This reminds me of the Cambridge Analytic facebook manipulation case that is well documented in the Netflix documentation <a href=\"https://www.netflix.com/Title/80117542\">The Great Hack</a>.</p>\n<h2 id=\"Data-Protection\"><a href=\"#Data-Protection\" class=\"headerlink\" title=\"Data Protection?\"></a>Data Protection?</h2><p>The EU General Data Protection Regulation (GDPR) should have protected us from mass surveillance, profiling and targeting in theory. But it did not, as the Snowden files showed. It seems almost impossible to use the internet without agreeing to Terms of Use beforehand, those contracts typically forces one into agreeing to the collection of ones personal data.<br>The author additionally notes that we cannot even assume those personal profiles to be reliable (to be accurate). He notes the chances digital twins behave identical to us are not very high.</p>\n<h2 id=\"Scoring-Citizen-Scores-Superscores\"><a href=\"#Scoring-Citizen-Scores-Superscores\" class=\"headerlink\" title=\"Scoring, Citizen Scores, Superscores\"></a>Scoring, Citizen Scores, Superscores</h2><p>Scoring is simillar to building a profile for people based on their personal data; however, it also assigns a value to peoples attributes, and data that eventually leads to a numerical value the score. Said value heavily inflicts one’s life as it determines products availabe for them or more generally how one is treated. China is currently testing this approach under the name “Social Credit Score”. According to the author the program may be seen as an attempt to make citizens obedient to the government’s wishes, which has been critized as data dictatorship or technological totalitarianism.</p>\n<h2 id=\"Automation-vs-Freedom\"><a href=\"#Automation-vs-Freedom\" class=\"headerlink\" title=\"Automation vs. Freedom\"></a>Automation vs. Freedom</h2><p>In the age of AI it is tempting to automate processes of all kinds, including decision making. The latter often involes (either explicitly or implicitly) evaluating based on an index or a one-dimensional descision function. It is tempting to decide in a statistical manner. However the author heavily argues against this, for it effectively eliminates free choice. Alternatively, he proposes a semi-automated approach that reduces the decisions humans have to make by deciding the sure cases, while leaving the complex cases for the humans to process.</p>\n<h2 id=\"Learning-to-Die\"><a href=\"#Learning-to-Die\" class=\"headerlink\" title=\"Learning to Die?\"></a>Learning to Die?</h2><h2 id=\"A-revolution-from-above\"><a href=\"#A-revolution-from-above\" class=\"headerlink\" title=\"A revolution from above?\"></a>A revolution from above?</h2><h2 id=\"Human-Rights\"><a href=\"#Human-Rights\" class=\"headerlink\" title=\"Human Rights\"></a>Human Rights</h2><p>According to the author human rights were established, due to the horrors of the twentiest century. He then goes on to say that the establishment of human rights is axiomatic for the foundation of modern civilizatin, which in turn is reflected by the UN’s Universal Declaration of Human Rights–to prevent such catastrophies from happening again in the future.</p>\n<p>As a student of Jordan Peterson and Alexandr Solzhenitsyn I could hardly disagree more. Firstly, I think it as wrong to proclaim that pre WW people had no human right. Can not the American constitution (as just one of many exmaples) be seen as proof for such a thing? Secondly, I believe that the burden to prevent a second 20th century is to solve at an individual level, and not by the UN or personal rights!<br>However, in the next sentence Dr. Helbing argues that the promoting of a materialistic consumption-driven society has led the the current (non-) sustainability crisis. With this I can partly agree.</p>\n<p>In the last paragraph the author points out that we would be living in a self sustaining world had the industrialized countries managed to reduce their resource consumption by 3% annually since the 1970s. I don’t really know what to make of this, since I don’t know any of the related literature.</p>\n<h2 id=\"Happiness-vs-Capitalism\"><a href=\"#Happiness-vs-Capitalism\" class=\"headerlink\" title=\"Happiness vs. Capitalism\"></a>Happiness vs. Capitalism</h2><p>Dr. Helbing argues that autonomy and good relationships are the best indicators for promoting personal happiness. He then goes saying, “I believe, if our soceity would be designed and managed in a way that supports the happiness of people, it would also be more sustainable, because happy people do not consume that much.” I do not agree with this hypothesis or believe it at least to be overly simplistic. How can we know that happy people consume less?</p>\n<p>However in the next paragraph the author points out that tech companies are partly to blame for the problems we are facing today. By their utilitarian practice of making users pay with their personal data and then selling that data to other companies, they might be seriously violating what we perceive as our right to privacy.</p>\n<h2 id=\"Human-Dignity\"><a href=\"#Human-Dignity\" class=\"headerlink\" title=\"Human Dignity\"></a>Human Dignity</h2><p>According to Dr. Helbing human dignity is given to us at birth and is axiomatic to societal values. The right to be treated as human towers above everything else. Politics and other institutions must do what they can, in order to proect human dignity from violations by public institutions etc. By not engaging in this practice public institutions lose their legitimacy.</p>\n<p>But what is human dignity? The author says that it means to be treated differently from objects and animals, but as human–this is yet again (also) mentioned in Turing’s paper on AI, where he explains that animals do not possess a soul in Christianity. It means to have the right to be involved in decisions and affaris that concern them, including the right of informational self-determination. Exposing people to unwanted mass surveillance is a clear violation of that.<br>At the end of the section Dr. Helbing proclaims: “I do, therefore, urge public and private actors to push informational self-determination forward quickly.”</p>\n<h2 id=\"Informational-Self-Determination\"><a href=\"#Informational-Self-Determination\" class=\"headerlink\" title=\"Informational Self-Determination\"></a>Informational Self-Determination</h2><p>I had to look up what is meant with informational self-determination. According to the Wikipedia article it is derived from the German word “informationelle Selbstbestimmung” and stands for the right for one to decide for himself what of his data should be communicated with others and what should be kept private.</p>\n<p>Dr. Helbing proposes a platform that would allow individuals to control which private data they allow a service to collect–and therefore allow them to use for e.g. personalized content, for which period of time, and perhabs for whichprice. The resulting competition for consumer trust could eventually promote a trustable digital society.</p>\n<p>According to the author this platform would create a level playing field, for not only big businesses but also small organizations could work with the data (access approved by the people).</p>\n<p>In Dr. Helbing’s own words in the last paragraph in this section: “Over time, if implemented well, such an approach would establish a thriving trustable digital age that empowers people, companies and governments alike, while making quick progress towards a sustainable and peaceful world.</p>\n<h2 id=\"Design-for-Values\"><a href=\"#Design-for-Values\" class=\"headerlink\" title=\"Design for Values\"></a>Design for Values</h2><h2 id=\"Democracy-by-Design\"><a href=\"#Democracy-by-Design\" class=\"headerlink\" title=\"Democracy by Design\"></a>Democracy by Design</h2><p>The author notes that among the social engineers of the digital age democracy has often been framed as outdated technology. </p>\n<p>The author then names “human dignity and human rights, (informational) self-determination, freedom (combined with accountability), pluralism, protection of minorities, division of power, checks and balances, participation, transparency, fairness, justice, legitimacy, anonymous and equal votes, and privacy” as relevant values for democracy.</p>\n<h2 id=\"Fairness\"><a href=\"#Fairness\" class=\"headerlink\" title=\"Fairness\"></a>Fairness</h2><p>The final topic on this paper is a discussion of the power of fairness: whether it is a good idea that everyone has a single vote. Contrary to European democratic values, shouldn’t smart people have more than one vote? According to the author experimental evidence about the “wisdom of crowds” surprisingly suggests, giving people different weights does not improve results. “On the contrary, studies in collective intelligence show that largely unequal influence on a debate will reduce social intelligence”, Dr. Helbing points out.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"AI-on-the-Rise\"><a href=\"#AI-on-the-Rise\" class=\"headerlink\" title=\"AI on the Rise\"></a>AI on the Rise</h2><p>The author delves into the topic by saying that AI is everywhere: automated driving (among other everyday appliations), digital assistants such as Siri, Alexa, Google Home are to be found more and more frequently.<br>This is followed by an interesting prediction from Ray Kurzweil who predicted that AI would have the power of an insectoid brain in the year 2000; the cognitive capabilities of a mouse brain in year 2010; human-like brain cognition around the year 2020; and eventually the power of <em>all human</em> brains in the middle of the century. Many think this merely techno-optimistic. This hyptothesis could be supported (or not) by successful AI projects such as the IBM Deep Blue computer, who beat chess genius Garry Kasparov in 1997, or Google’s AlphaGo system which beat the reigning world champion Lee Sedol in the strategy game “Go” in 2016.<br>Here is another example from an old personal interest of mine: the real-time strategy (video) game Starcraft II. Many consider Starcraft a truly hard game among games. It is often said–in an impolite manner among players–that Starcraft is much more complex than your MOBA of choice (be it DOTA or League of Legends). Korean players have dominated the scene over years with their (almost) impeccable execution. It takes years too master Starcraft and many players dedicated years of their life to do so. Last year in 2019 ,as I am writing this, on December the 19th an AI called AlphaStar beat TLO’s legend MaNa under tournament condition in best of five 5-0! The games were played under tournament condition (as known from the WCS). For further reading head to this very insightful article on deepmind.com: <a href=\"https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii\">AlphaStar: Mastering the Real-Time Strategy Game StarCraft II</a>. I would like to add that the article did not mention whether AlphaStar was tested against Korean players. I would also like to know whether other matchups than PvP were played.</p>\n<h2 id=\"AI-as-God\"><a href=\"#AI-as-God\" class=\"headerlink\" title=\"AI as God\"></a>AI as God</h2><p>Apparently former Google engineer Anthony Levandovski is dead-serious about starting a religion whose deity is an AI. Levandowski says the new religion, “Way of the Future,” will focus on “the realization, acceptance, and worship of a Godhead based on AI developed through computer hardware and software.”<br>The article then mentions that we are (and have been for some years) heavily influenced by AI algorithms. The TED talk <a href=\"https://www.youtube.com/watch?v=C74amJRp730\">How a handful of tech companies control billions of minds every day</a> by Tristan Harris–another former Google employee who talks about people in a control room who literally control the way we think. This really got me to think on how heavily I am being manipulated–for I believe to know that I can be manipulated are probably are.</p>\n<h2 id=\"Singularity\"><a href=\"#Singularity\" class=\"headerlink\" title=\"Singularity\"></a>Singularity</h2><p>The word singularity has multiple meanings. I think the following (from merriam webster) is the most fitting in this context: </p>\n<blockquote>\n<p>a point at which the derivative of a given function of a complex variable does not exist but every neighborhood of which contains points for which the derivative does exist</p>\n</blockquote>\n<p>Unfortunately, I do not understand calculus with complex numbers. However, from what I understand this means that there exists a certain (complex) point on a graph to which no derivativ exists.<br>According to Wikipedia the term technical technology is (neatly) defined as follows: </p>\n<blockquote>\n<p>the singularity is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization</p>\n</blockquote>\n<p>In as early as the 1960s, computer scientists already conjectured about what they call intelligence explosion–the point where exponential growth supersedes human-like intelligence in a manner that can be considered the singularity. I. J. Good speculated: </p>\n<blockquote>\n<p>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.</p>\n</blockquote>\n<p>This took me back to Alan Turing’s paper “Computing Machinery and Intelligence”, which I had done a presention on for English class. My presentation mostly used the eccentricities of the paper and shocked people with the fact that Turing believed in the existence of telepathy and that his paper contained a discussion on religion–which I believe he took dead-serious, found in the section “The Theological Objection”. Turing’s thoughts on whether “hard”-AIs can be built can be found in the paper in the Section “Learning Machines”. Plus, Turing went as far as to include his thoughts on how such a hypothecial machine might be trained. A very good read, especially, when one keeps in mind that Turing wrote this in 1950 when computers filled whole rooms!</p>\n<p>Furthermore, I learned from Wikipedia, that it was John von Neumann who came up with the word singluarity (in the technical context). Curious as I was I clicked on the the hyperlink to <a href=\"https://en.wikipedia.org/wiki/John_von_Neumann\">Neumann’s article</a> to learn that he was a higly impressive Mathematician. I knew his name from the <a href=\"https://en.wikipedia.org/wiki/Von_Neumann_architecture\">von Neumann architecture</a> (a model for low-level CPU architecture). But this was, as I now understand, just one of his accomplishments. He is, among other things, the founder of Game Theory.</p>\n<p>The article poses the question whether a singularity is likely and mentions some popular outcries for caution. Stephen Hawking with a evolutionary argument: “Humans, who are limited by slow biological evolution, couldn’t compete and would be superseded.” and as I have read many times in everyday media Elon Musk has the following to say: “We should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it’s probably that.” For more details on the latter one could listen the The Podcast Episode <a href=\"https://www.youtube.com/watch?v=RcYjXbSJBN8\">Joe Rogan Experience #1470 - Elon Musk</a>, and not for the fact that Mr. Musk is smoking pot on “air”, but for the relaxed discussion of AI.<br>Therefore, it is time to ask the question, what whill happen with humans and humanity after the singularity?, Dirk Helbing goes on. There are different views on the subject, one of them (Schmidhuber) claims that superintelligent robots will be as little interested in humans as we are in ants, but this does not imply that there would be no conflict for resources. Others fear for unenployment on a large scale. And then there is an optimistic viewpoint with the belief in an utopian world, the so called “Second Machine Age”.</p>\n<h2 id=\"Transhumanism\"><a href=\"#Transhumanism\" class=\"headerlink\" title=\"Transhumanism\"></a>Transhumanism</h2><p>Taken from the article on <a href=\"https://en.wikipedia.org/wiki/Transhumanism\">Transhumanism</a> on Wikipedia:</p>\n<blockquote>\n<p>Transhumanist thinkers study the potential benefits and dangers of emerging technologies that could overcome fundamental human limitations as well as the ethical limitations of using such technologies. The most common transhumanist thesis is that human beings may eventually be able to transform themselves into different beings with abilities so greatly expanded from the current condition as to merit the label of posthuman beings.</p>\n</blockquote>\n<p>The article notes that not only is the future of humanity up for debate, but also human existence itself. Some, among those is Elon Musk, believe that humans will need augmentations to stay on level with AI and to eventually merge with it.</p>\n<h2 id=\"Is-AI-really-intelligent\"><a href=\"#Is-AI-really-intelligent\" class=\"headerlink\" title=\"Is AI really intelligent?\"></a>Is AI really intelligent?</h2><p>This must be my favourite part of the paper. Here, Dr. Helbing shares his own views with us on the currently existing “soft”-AIs.<br>In order to determine the true intelligence quality of AIs he considers whether they are autonomous, capable of emotion, capable of creativity, and conscious.<br>This reminds me, yet again, to Turing’s paper, who also tried to determine whether a computer could be capable of writing a sonnet. Dr. Helbing thinks that AI’s are not autonomous, because they require human maintenance and external resources (also) provided by humans; thinks that AI systems are not capapble of emotion, due to the fact that mimicking emotion is not the same as actually feeling an emotion; and to the question whether he thinks that AI systems are conscious he answers simply: I would say “no”, by argueing that we do not yet understand consciousness at all.<br>At the end of this section the author notes that attemping to create humanoid robots might teach us a lesson or two about what love or consciousness is–then how are we supposed to create what we do not yet understand.<br>I will dare to add a personal note here. I do not yet understand the current neuroscience literature at all. In my bookshelf at home sits a book on consciousness and I haven’t touched the bloody thing yet. I know about as much about love, but I liked Brené Brown’s definition of it. In case you are interested in reading a definition of love, look on her website on <a href=\"https://brenebrown.com/definitions/\">https://brenebrown.com/definitions/</a>.</p>\n<h2 id=\"What-is-consciousness\"><a href=\"#What-is-consciousness\" class=\"headerlink\" title=\"What is consciousness\"></a>What is consciousness</h2><p>This part discusses the conjecture that world is an interpretation of higher-dimensional data. Furthermore the world was not limited to three dimension, but it is us who can only perceive it that way. Then as the author notes, the permanent distractions by the attention economy would just be the opposite of what would be needed to advance humanity.<br>To make this more plausible the following example is given: consider why Egyptian and ancient paintings look flat, i.e. two-dimensional. Did ancient people see the world with <em>literally</em> different eyes? This is interesting to think about, however I think it is too simplistic and narrow minded in it’s analysis.</p>\n<h2 id=\"Big-Data-Analytics\"><a href=\"#Big-Data-Analytics\" class=\"headerlink\" title=\"Big Data Analytics\"></a>Big Data Analytics</h2><p>Chris Anderson claimed in an article in “Wired” magazine in 2008 that the scientific method would soon be obsolete due to Big Data Analysis. Simplified, that if one had just enough data, data quntity could be turned into data quality and thus the truth would eventually reveal itself.<br>However, so far it seems to be harder than perhabs anticipated to harvest meaningful data. This seems to stem in part from false positives.</p>\n<h2 id=\"Correlation-vs-Causality\"><a href=\"#Correlation-vs-Causality\" class=\"headerlink\" title=\"Correlation vs. Causality\"></a>Correlation vs. Causality</h2><p>In Big Data patterns and correlations are easily found. However, one can not make any conclusions from said correlations. The following example is given: consider the correlation between the number of ice-cream-eating children and the number of forest fires. Forbidding children to eat ice cream will obviously not reduce the number of forest fires at all–despite the strong correlation in the data. It is obviously a third factor that causes both increased ince cream consumption and forest fires!</p>\n<h2 id=\"Trustable-AI\"><a href=\"#Trustable-AI\" class=\"headerlink\" title=\"Trustable AI\"></a>Trustable AI</h2><p>Ideally we could use AI to make sense of Big Data for us. However, according to Dr. Helbing AI’s can only do this partly due to the fact that they show bias against women, non-white people, or minorities–this happens because they are usually trained with data of the past. Additionally, an AI can not explain it’s own action, which could lead to a sitation where e.g. your application for a loan or life insurance is turned down, but nobody can tell you why.</p>\n<h2 id=\"Profiling-Targeting-and-Digital-Twins\"><a href=\"#Profiling-Targeting-and-Digital-Twins\" class=\"headerlink\" title=\"Profiling, Targeting, and Digital Twins\"></a>Profiling, Targeting, and Digital Twins</h2><p>Thanks to the Edward Snowden leaks, we know that (at least) the American intelligence services have been running mass surveillance programs under the guise of fighting terrorism. Doing this, they created “profiles” of everyone. Dr. Elbing says “You may imagine this like a black box that has been crated for everyone, which is continuously fed with surveillance data and learns to behave like the humans they are imitating.” Such systems can be used to personalize information and finally manipulate our behaviour in the way (most desirable) to the highest bidder.<br>This reminds me of the Cambridge Analytic facebook manipulation case that is well documented in the Netflix documentation <a href=\"https://www.netflix.com/Title/80117542\">The Great Hack</a>.</p>\n<h2 id=\"Data-Protection\"><a href=\"#Data-Protection\" class=\"headerlink\" title=\"Data Protection?\"></a>Data Protection?</h2><p>The EU General Data Protection Regulation (GDPR) should have protected us from mass surveillance, profiling and targeting in theory. But it did not, as the Snowden files showed. It seems almost impossible to use the internet without agreeing to Terms of Use beforehand, those contracts typically forces one into agreeing to the collection of ones personal data.<br>The author additionally notes that we cannot even assume those personal profiles to be reliable (to be accurate). He notes the chances digital twins behave identical to us are not very high.</p>\n<h2 id=\"Scoring-Citizen-Scores-Superscores\"><a href=\"#Scoring-Citizen-Scores-Superscores\" class=\"headerlink\" title=\"Scoring, Citizen Scores, Superscores\"></a>Scoring, Citizen Scores, Superscores</h2><p>Scoring is simillar to building a profile for people based on their personal data; however, it also assigns a value to peoples attributes, and data that eventually leads to a numerical value the score. Said value heavily inflicts one’s life as it determines products availabe for them or more generally how one is treated. China is currently testing this approach under the name “Social Credit Score”. According to the author the program may be seen as an attempt to make citizens obedient to the government’s wishes, which has been critized as data dictatorship or technological totalitarianism.</p>\n<h2 id=\"Automation-vs-Freedom\"><a href=\"#Automation-vs-Freedom\" class=\"headerlink\" title=\"Automation vs. Freedom\"></a>Automation vs. Freedom</h2><p>In the age of AI it is tempting to automate processes of all kinds, including decision making. The latter often involes (either explicitly or implicitly) evaluating based on an index or a one-dimensional descision function. It is tempting to decide in a statistical manner. However the author heavily argues against this, for it effectively eliminates free choice. Alternatively, he proposes a semi-automated approach that reduces the decisions humans have to make by deciding the sure cases, while leaving the complex cases for the humans to process.</p>\n<h2 id=\"Learning-to-Die\"><a href=\"#Learning-to-Die\" class=\"headerlink\" title=\"Learning to Die?\"></a>Learning to Die?</h2><h2 id=\"A-revolution-from-above\"><a href=\"#A-revolution-from-above\" class=\"headerlink\" title=\"A revolution from above?\"></a>A revolution from above?</h2><h2 id=\"Human-Rights\"><a href=\"#Human-Rights\" class=\"headerlink\" title=\"Human Rights\"></a>Human Rights</h2><p>According to the author human rights were established, due to the horrors of the twentiest century. He then goes on to say that the establishment of human rights is axiomatic for the foundation of modern civilizatin, which in turn is reflected by the UN’s Universal Declaration of Human Rights–to prevent such catastrophies from happening again in the future.</p>\n<p>As a student of Jordan Peterson and Alexandr Solzhenitsyn I could hardly disagree more. Firstly, I think it as wrong to proclaim that pre WW people had no human right. Can not the American constitution (as just one of many exmaples) be seen as proof for such a thing? Secondly, I believe that the burden to prevent a second 20th century is to solve at an individual level, and not by the UN or personal rights!<br>However, in the next sentence Dr. Helbing argues that the promoting of a materialistic consumption-driven society has led the the current (non-) sustainability crisis. With this I can partly agree.</p>\n<p>In the last paragraph the author points out that we would be living in a self sustaining world had the industrialized countries managed to reduce their resource consumption by 3% annually since the 1970s. I don’t really know what to make of this, since I don’t know any of the related literature.</p>\n<h2 id=\"Happiness-vs-Capitalism\"><a href=\"#Happiness-vs-Capitalism\" class=\"headerlink\" title=\"Happiness vs. Capitalism\"></a>Happiness vs. Capitalism</h2><p>Dr. Helbing argues that autonomy and good relationships are the best indicators for promoting personal happiness. He then goes saying, “I believe, if our soceity would be designed and managed in a way that supports the happiness of people, it would also be more sustainable, because happy people do not consume that much.” I do not agree with this hypothesis or believe it at least to be overly simplistic. How can we know that happy people consume less?</p>\n<p>However in the next paragraph the author points out that tech companies are partly to blame for the problems we are facing today. By their utilitarian practice of making users pay with their personal data and then selling that data to other companies, they might be seriously violating what we perceive as our right to privacy.</p>\n<h2 id=\"Human-Dignity\"><a href=\"#Human-Dignity\" class=\"headerlink\" title=\"Human Dignity\"></a>Human Dignity</h2><p>According to Dr. Helbing human dignity is given to us at birth and is axiomatic to societal values. The right to be treated as human towers above everything else. Politics and other institutions must do what they can, in order to proect human dignity from violations by public institutions etc. By not engaging in this practice public institutions lose their legitimacy.</p>\n<p>But what is human dignity? The author says that it means to be treated differently from objects and animals, but as human–this is yet again (also) mentioned in Turing’s paper on AI, where he explains that animals do not possess a soul in Christianity. It means to have the right to be involved in decisions and affaris that concern them, including the right of informational self-determination. Exposing people to unwanted mass surveillance is a clear violation of that.<br>At the end of the section Dr. Helbing proclaims: “I do, therefore, urge public and private actors to push informational self-determination forward quickly.”</p>\n<h2 id=\"Informational-Self-Determination\"><a href=\"#Informational-Self-Determination\" class=\"headerlink\" title=\"Informational Self-Determination\"></a>Informational Self-Determination</h2><p>I had to look up what is meant with informational self-determination. According to the Wikipedia article it is derived from the German word “informationelle Selbstbestimmung” and stands for the right for one to decide for himself what of his data should be communicated with others and what should be kept private.</p>\n<p>Dr. Helbing proposes a platform that would allow individuals to control which private data they allow a service to collect–and therefore allow them to use for e.g. personalized content, for which period of time, and perhabs for whichprice. The resulting competition for consumer trust could eventually promote a trustable digital society.</p>\n<p>According to the author this platform would create a level playing field, for not only big businesses but also small organizations could work with the data (access approved by the people).</p>\n<p>In Dr. Helbing’s own words in the last paragraph in this section: “Over time, if implemented well, such an approach would establish a thriving trustable digital age that empowers people, companies and governments alike, while making quick progress towards a sustainable and peaceful world.</p>\n<h2 id=\"Design-for-Values\"><a href=\"#Design-for-Values\" class=\"headerlink\" title=\"Design for Values\"></a>Design for Values</h2><h2 id=\"Democracy-by-Design\"><a href=\"#Democracy-by-Design\" class=\"headerlink\" title=\"Democracy by Design\"></a>Democracy by Design</h2><p>The author notes that among the social engineers of the digital age democracy has often been framed as outdated technology. </p>\n<p>The author then names “human dignity and human rights, (informational) self-determination, freedom (combined with accountability), pluralism, protection of minorities, division of power, checks and balances, participation, transparency, fairness, justice, legitimacy, anonymous and equal votes, and privacy” as relevant values for democracy.</p>\n<h2 id=\"Fairness\"><a href=\"#Fairness\" class=\"headerlink\" title=\"Fairness\"></a>Fairness</h2><p>The final topic on this paper is a discussion of the power of fairness: whether it is a good idea that everyone has a single vote. Contrary to European democratic values, shouldn’t smart people have more than one vote? According to the author experimental evidence about the “wisdom of crowds” surprisingly suggests, giving people different weights does not improve results. “On the contrary, studies in collective intelligence show that largely unequal influence on a debate will reduce social intelligence”, Dr. Helbing points out.</p>\n"},{"title":"Part 2––thoughts on AI","date":"2020-11-03T19:08:39.000Z","_content":"It is now the 8th week of my second to last semester at zhaw for my bachelor degree in computer science. My professor gave me the assignment to write about my thinking on AI technology: especially how it (my thinking) has evolved since taking the course.  \nAs a baseline, I was given the article [The Seven Deadly Sins of AI Predictions](https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/) by Rodney Brooks; which I found to be eloquently written as well as inspiring.\n\nWriting this piece is difficult because there is only so little that I understand about the AI field, even after taking a course on the subject for more than 8 weeks!  \nI have tried to read in the book \"Artificial Intelligence - a modern approach\"--we call it the AIAMA book in shorthand-- as much as possible, but only to managed as far as the second chapter so far. Recently I learned that Stuart Russel, while being a professor of computer science, also functions as an adjunct Professor of Neurological Surgery--this somewhat explains the precision in his writings on AI and neuroscience where he seems equally fluent in both!\n\nI used to feel ashamed for not having some basic knowledge on \"Machine Learning\" or AI; this would go as far as that I would pretend otherwise or try to navigate away from the topic. Shouldn't I as a computer programmer and computer science undergraduate know about these topics? I still do not understand them but at last, I longer feel the shame that originally went along with it--for they are incredibly complex topics and many people merely pretend to understand them.\n\n### As we may think\nDuring the last 2 months, much of my attention has been spent reading historical papers. I --and I truly wish this were different-- have very little time to read, and I ended up spending less time on my AI class then I wanted too. Hopefully, I will manage to read most of the AIAMA book until the end of the semester ...  \nHowever, I did manage to read Vannevar Bush's article \"As we may think\" as well as a brilliant paper by Mark Sanderson, W. Bruce Croft titled \"The History of Information Retrieval Research\". You might have noticed that those papers are arguably more relevant to the field of IE (Information Retrieval) and you would be right. However, I found--and I might just be completely wrong about that--the two fields to share many similarities. Also, \"As we may think\" is a brilliant piece, truly inspiring and really not that far off: if you put aside the insistence on microfilm and dry-film as the technology to be used for digital-like imagery. Today it occurred to me that modern devices such as the Microsoft Surface tablets with pens or Apple's new iPad Pros come daringly close to Bushs's vision he described as the Memex device.  \nHowever, while table-like devices have been developed I think Bush was wrong to assume--or maybe hope--that they would be used for people to conduct diligent research and share thoughts. Am I wrong to assume that iPads are mostly used media consumption? I think not, however, the Microsoft Surface tablets are mostly used on colleges by students or employees in business--and that means my original assumption is most likely narrow-minded.\n\n### The History of AI\nIt is interesting to learn that in both fields IE and AI much of the groundwork has been laid a long time ago: neural nets were first mentioned by  Warren McCulloch and Walter Pitts in 1943 1) and the vector space model (the most prevalent model in use) goes back to P. Switzer in 1963. This seems rather bizarre, giving the fact that the first happened almost 50 years before I was born; and yet computer science has this air of a *relatively* fresh field.  \nEven more interesting to me were the early ideas of logical machines. Those are found both in the paper on the history of IE and in V. Bush's article. This leads me to another class that I am taking called programming languages and paradigms, where we learn, among other things, about the programming language Prolog. Did the motivation behind Prolog start with the logic machines mentioned by Bush or was it uniquely suitable to solve early AI problems? I hope to find out.","source":"_posts/part-two-thoughts-on-ai.md","raw":"---\ntitle: Part 2––thoughts on AI\ndate: 2020-11-03 20:08:39\ntags:\n---\nIt is now the 8th week of my second to last semester at zhaw for my bachelor degree in computer science. My professor gave me the assignment to write about my thinking on AI technology: especially how it (my thinking) has evolved since taking the course.  \nAs a baseline, I was given the article [The Seven Deadly Sins of AI Predictions](https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/) by Rodney Brooks; which I found to be eloquently written as well as inspiring.\n\nWriting this piece is difficult because there is only so little that I understand about the AI field, even after taking a course on the subject for more than 8 weeks!  \nI have tried to read in the book \"Artificial Intelligence - a modern approach\"--we call it the AIAMA book in shorthand-- as much as possible, but only to managed as far as the second chapter so far. Recently I learned that Stuart Russel, while being a professor of computer science, also functions as an adjunct Professor of Neurological Surgery--this somewhat explains the precision in his writings on AI and neuroscience where he seems equally fluent in both!\n\nI used to feel ashamed for not having some basic knowledge on \"Machine Learning\" or AI; this would go as far as that I would pretend otherwise or try to navigate away from the topic. Shouldn't I as a computer programmer and computer science undergraduate know about these topics? I still do not understand them but at last, I longer feel the shame that originally went along with it--for they are incredibly complex topics and many people merely pretend to understand them.\n\n### As we may think\nDuring the last 2 months, much of my attention has been spent reading historical papers. I --and I truly wish this were different-- have very little time to read, and I ended up spending less time on my AI class then I wanted too. Hopefully, I will manage to read most of the AIAMA book until the end of the semester ...  \nHowever, I did manage to read Vannevar Bush's article \"As we may think\" as well as a brilliant paper by Mark Sanderson, W. Bruce Croft titled \"The History of Information Retrieval Research\". You might have noticed that those papers are arguably more relevant to the field of IE (Information Retrieval) and you would be right. However, I found--and I might just be completely wrong about that--the two fields to share many similarities. Also, \"As we may think\" is a brilliant piece, truly inspiring and really not that far off: if you put aside the insistence on microfilm and dry-film as the technology to be used for digital-like imagery. Today it occurred to me that modern devices such as the Microsoft Surface tablets with pens or Apple's new iPad Pros come daringly close to Bushs's vision he described as the Memex device.  \nHowever, while table-like devices have been developed I think Bush was wrong to assume--or maybe hope--that they would be used for people to conduct diligent research and share thoughts. Am I wrong to assume that iPads are mostly used media consumption? I think not, however, the Microsoft Surface tablets are mostly used on colleges by students or employees in business--and that means my original assumption is most likely narrow-minded.\n\n### The History of AI\nIt is interesting to learn that in both fields IE and AI much of the groundwork has been laid a long time ago: neural nets were first mentioned by  Warren McCulloch and Walter Pitts in 1943 1) and the vector space model (the most prevalent model in use) goes back to P. Switzer in 1963. This seems rather bizarre, giving the fact that the first happened almost 50 years before I was born; and yet computer science has this air of a *relatively* fresh field.  \nEven more interesting to me were the early ideas of logical machines. Those are found both in the paper on the history of IE and in V. Bush's article. This leads me to another class that I am taking called programming languages and paradigms, where we learn, among other things, about the programming language Prolog. Did the motivation behind Prolog start with the logic machines mentioned by Bush or was it uniquely suitable to solve early AI problems? I hope to find out.","slug":"part-two-thoughts-on-ai","published":1,"updated":"2020-11-03T19:14:35.116Z","_id":"ckh2cjvo90000a0108n6h6ixw","comments":1,"layout":"post","photos":[],"link":"","content":"<p>It is now the 8th week of my second to last semester at zhaw for my bachelor degree in computer science. My professor gave me the assignment to write about my thinking on AI technology: especially how it (my thinking) has evolved since taking the course.<br>As a baseline, I was given the article <a href=\"https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/\">The Seven Deadly Sins of AI Predictions</a> by Rodney Brooks; which I found to be eloquently written as well as inspiring.</p>\n<p>Writing this piece is difficult because there is only so little that I understand about the AI field, even after taking a course on the subject for more than 8 weeks!<br>I have tried to read in the book “Artificial Intelligence - a modern approach”–we call it the AIAMA book in shorthand– as much as possible, but only to managed as far as the second chapter so far. Recently I learned that Stuart Russel, while being a professor of computer science, also functions as an adjunct Professor of Neurological Surgery–this somewhat explains the precision in his writings on AI and neuroscience where he seems equally fluent in both!</p>\n<p>I used to feel ashamed for not having some basic knowledge on “Machine Learning” or AI; this would go as far as that I would pretend otherwise or try to navigate away from the topic. Shouldn’t I as a computer programmer and computer science undergraduate know about these topics? I still do not understand them but at last, I longer feel the shame that originally went along with it–for they are incredibly complex topics and many people merely pretend to understand them.</p>\n<h3 id=\"As-we-may-think\"><a href=\"#As-we-may-think\" class=\"headerlink\" title=\"As we may think\"></a>As we may think</h3><p>During the last 2 months, much of my attention has been spent reading historical papers. I –and I truly wish this were different– have very little time to read, and I ended up spending less time on my AI class then I wanted too. Hopefully, I will manage to read most of the AIAMA book until the end of the semester …<br>However, I did manage to read Vannevar Bush’s article “As we may think” as well as a brilliant paper by Mark Sanderson, W. Bruce Croft titled “The History of Information Retrieval Research”. You might have noticed that those papers are arguably more relevant to the field of IE (Information Retrieval) and you would be right. However, I found–and I might just be completely wrong about that–the two fields to share many similarities. Also, “As we may think” is a brilliant piece, truly inspiring and really not that far off: if you put aside the insistence on microfilm and dry-film as the technology to be used for digital-like imagery. Today it occurred to me that modern devices such as the Microsoft Surface tablets with pens or Apple’s new iPad Pros come daringly close to Bushs’s vision he described as the Memex device.<br>However, while table-like devices have been developed I think Bush was wrong to assume–or maybe hope–that they would be used for people to conduct diligent research and share thoughts. Am I wrong to assume that iPads are mostly used media consumption? I think not, however, the Microsoft Surface tablets are mostly used on colleges by students or employees in business–and that means my original assumption is most likely narrow-minded.</p>\n<h3 id=\"The-History-of-AI\"><a href=\"#The-History-of-AI\" class=\"headerlink\" title=\"The History of AI\"></a>The History of AI</h3><p>It is interesting to learn that in both fields IE and AI much of the groundwork has been laid a long time ago: neural nets were first mentioned by  Warren McCulloch and Walter Pitts in 1943 1) and the vector space model (the most prevalent model in use) goes back to P. Switzer in 1963. This seems rather bizarre, giving the fact that the first happened almost 50 years before I was born; and yet computer science has this air of a <em>relatively</em> fresh field.<br>Even more interesting to me were the early ideas of logical machines. Those are found both in the paper on the history of IE and in V. Bush’s article. This leads me to another class that I am taking called programming languages and paradigms, where we learn, among other things, about the programming language Prolog. Did the motivation behind Prolog start with the logic machines mentioned by Bush or was it uniquely suitable to solve early AI problems? I hope to find out.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>It is now the 8th week of my second to last semester at zhaw for my bachelor degree in computer science. My professor gave me the assignment to write about my thinking on AI technology: especially how it (my thinking) has evolved since taking the course.<br>As a baseline, I was given the article <a href=\"https://www.technologyreview.com/2017/10/06/241837/the-seven-deadly-sins-of-ai-predictions/\">The Seven Deadly Sins of AI Predictions</a> by Rodney Brooks; which I found to be eloquently written as well as inspiring.</p>\n<p>Writing this piece is difficult because there is only so little that I understand about the AI field, even after taking a course on the subject for more than 8 weeks!<br>I have tried to read in the book “Artificial Intelligence - a modern approach”–we call it the AIAMA book in shorthand– as much as possible, but only to managed as far as the second chapter so far. Recently I learned that Stuart Russel, while being a professor of computer science, also functions as an adjunct Professor of Neurological Surgery–this somewhat explains the precision in his writings on AI and neuroscience where he seems equally fluent in both!</p>\n<p>I used to feel ashamed for not having some basic knowledge on “Machine Learning” or AI; this would go as far as that I would pretend otherwise or try to navigate away from the topic. Shouldn’t I as a computer programmer and computer science undergraduate know about these topics? I still do not understand them but at last, I longer feel the shame that originally went along with it–for they are incredibly complex topics and many people merely pretend to understand them.</p>\n<h3 id=\"As-we-may-think\"><a href=\"#As-we-may-think\" class=\"headerlink\" title=\"As we may think\"></a>As we may think</h3><p>During the last 2 months, much of my attention has been spent reading historical papers. I –and I truly wish this were different– have very little time to read, and I ended up spending less time on my AI class then I wanted too. Hopefully, I will manage to read most of the AIAMA book until the end of the semester …<br>However, I did manage to read Vannevar Bush’s article “As we may think” as well as a brilliant paper by Mark Sanderson, W. Bruce Croft titled “The History of Information Retrieval Research”. You might have noticed that those papers are arguably more relevant to the field of IE (Information Retrieval) and you would be right. However, I found–and I might just be completely wrong about that–the two fields to share many similarities. Also, “As we may think” is a brilliant piece, truly inspiring and really not that far off: if you put aside the insistence on microfilm and dry-film as the technology to be used for digital-like imagery. Today it occurred to me that modern devices such as the Microsoft Surface tablets with pens or Apple’s new iPad Pros come daringly close to Bushs’s vision he described as the Memex device.<br>However, while table-like devices have been developed I think Bush was wrong to assume–or maybe hope–that they would be used for people to conduct diligent research and share thoughts. Am I wrong to assume that iPads are mostly used media consumption? I think not, however, the Microsoft Surface tablets are mostly used on colleges by students or employees in business–and that means my original assumption is most likely narrow-minded.</p>\n<h3 id=\"The-History-of-AI\"><a href=\"#The-History-of-AI\" class=\"headerlink\" title=\"The History of AI\"></a>The History of AI</h3><p>It is interesting to learn that in both fields IE and AI much of the groundwork has been laid a long time ago: neural nets were first mentioned by  Warren McCulloch and Walter Pitts in 1943 1) and the vector space model (the most prevalent model in use) goes back to P. Switzer in 1963. This seems rather bizarre, giving the fact that the first happened almost 50 years before I was born; and yet computer science has this air of a <em>relatively</em> fresh field.<br>Even more interesting to me were the early ideas of logical machines. Those are found both in the paper on the history of IE and in V. Bush’s article. This leads me to another class that I am taking called programming languages and paradigms, where we learn, among other things, about the programming language Prolog. Did the motivation behind Prolog start with the logic machines mentioned by Bush or was it uniquely suitable to solve early AI problems? I hope to find out.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}