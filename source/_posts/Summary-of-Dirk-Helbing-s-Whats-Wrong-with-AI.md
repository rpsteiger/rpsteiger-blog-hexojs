---
title: Summary of Dirk Helbing's 'Whats Wrong with AI?'
date: 2020-09-06 23:52:16
tags:
---

## AI on the Rise
The author delves into the topic by saying that AI is everywhere: automated driving (among other everyday appliations), digital assistants such as Siri, Alexa, Google Home are to be found more and more frequently.  
This is followed by an interesting prediction from Ray Kurzweil who predicted that AI would have the power of an insectoid brain in the year 2000; the cognitive capabilities of a mouse brain in year 2010; human-like brain cognition around the year 2020; and eventually the power of _all human_ brains in the middle of the century. Many think this merely techno-optimistic. This hyptothesis could be supported (or not) by successful AI projects such as the IBM Deep Blue computer, who beat chess genius Garry Kasparov in 1997, or Google's AlphaGo system which beat the reigning world champion Lee Sedol in the strategy game "Go" in 2016.  
Here is another example from an old personal interest of mine: the real-time strategy (video) game Starcraft II. Many consider Starcraft a truly hard game among games. It is often said--in an impolite manner among players--that Starcraft is much more complex than your MOBA of choice (be it DOTA or League of Legends). Korean players have dominated the scene over years with their (almost) impeccable execution. It takes years too master Starcraft and many players dedicated years of their life to do so. Last year in 2019 ,as I am writing this, on December the 19th an AI called AlphaStar beat TLO's legend MaNa under tournament condition in best of five 5-0! The games were played under tournament condition (as known from the WCS). For further reading head to this very insightful article on deepmind.com: [AlphaStar: Mastering the Real-Time Strategy Game StarCraft II](https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii). I would like to add that the article did not mention whether AlphaStar was tested against Korean players. I would also like to know whether other matchups than PvP were played.

## AI as God
Apparently former Google engineer Anthony Levandovski is dead-serious about starting a religion whose deity is an AI. Levandowski says the new religion, “Way of the Future,” will focus on “the realization, acceptance, and worship of a Godhead based on AI developed through computer hardware and software.”  
The article then mentions that we are (and have been for some years) heavily influenced by AI algorithms. The TED talk [How a handful of tech companies control billions of minds every day](https://www.youtube.com/watch?v=C74amJRp730) by Tristan Harris--another former Google employee who talks about people in a control room who literally control the way we think. This really got me to think on how heavily I am being manipulated--for I believe to know that I can be manipulated are probably are.

## Singularity
The word singularity has multiple meanings. I think the following (from merriam webster) is the most fitting in this context: 
> a point at which the derivative of a given function of a complex variable does not exist but every neighborhood of which contains points for which the derivative does exist

Unfortunately, I do not understand calculus with complex numbers. However, from what I understand this means that there exists a certain (complex) point on a graph to which no derivativ exists.  
According to Wikipedia the term technical technology is (neatly) defined as follows: 
> the singularity is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization

In as early as the 1960s, computer scientists already conjectured about what they call intelligence explosion--the point where exponential growth supersedes human-like intelligence in a manner that can be considered the singularity. I. J. Good speculated: 
>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.

This took me back to Alan Turing's paper "Computing Machinery and Intelligence", which I had done a presention on for English class. My presentation mostly used the eccentricities of the paper and shocked people with the fact that Turing believed in the existence of telepathy and that his paper contained a discussion on religion--which I believe he took dead-serious, found in the section "The Theological Objection". Turing's thoughts on whether "hard"-AIs can be built can be found in the paper in the Section "Learning Machines". Plus, Turing went as far as to include his thoughts on how such a hypothecial machine might be trained. A very good read, especially, when one keeps in mind that Turing wrote this in 1950 when computers filled whole rooms!

Furthermore, I learned from Wikipedia, that it was John von Neumann who came up with the word singluarity (in the technical context). Curious as I was I clicked on the the hyperlink to [Neumann's article](https://en.wikipedia.org/wiki/John_von_Neumann) to learn that he was a higly impressive Mathematician. I knew his name from the [von Neumann architecture](https://en.wikipedia.org/wiki/Von_Neumann_architecture) (a model for low-level CPU architecture). But this was, as I now understand, just one of his accomplishments. He is, among other things, the founder of Game Theory.

The article poses the question whether a singularity is likely and mentions some popular outcries for caution. Stephen Hawking with a evolutionary argument: "Humans, who are limited by slow biological evolution, couldn't compete and would be superseded." and as I have read many times in everyday media Elon Musk has the following to say: "We should be very careful about artificial intelligence. If I had to guess at what our biggest existential threat is, it's probably that." For more details on the latter one could listen the The Podcast Episode [Joe Rogan Experience #1470 - Elon Musk](https://www.youtube.com/watch?v=RcYjXbSJBN8), and not for the fact that Mr. Musk is smoking pot on "air", but for the relaxed discussion of AI.  
Therefore, it is time to ask the question, what whill happen with humans and humanity after the singularity?, Dirk Helbing goes on. There are different views on the subject, one of them (Schmidhuber) claims that superintelligent robots will be as little interested in humans as we are in ants, but this does not imply that there would be no conflict for resources. Others fear for unenployment on a large scale. And then there is an optimistic viewpoint with the belief in an utopian world, the so called "Second Machine Age".

## Transhumanism
Taken from the article on [Transhumanism](https://en.wikipedia.org/wiki/Transhumanism) on Wikipedia:
> Transhumanist thinkers study the potential benefits and dangers of emerging technologies that could overcome fundamental human limitations as well as the ethical limitations of using such technologies. The most common transhumanist thesis is that human beings may eventually be able to transform themselves into different beings with abilities so greatly expanded from the current condition as to merit the label of posthuman beings.

The article notes that not only is the future of humanity up for debate, but also human existence itself. Some, among those is Elon Musk, believe that humans will need augmentations to stay on level with AI and to eventually merge with it.

## Is AI really intelligent?
This must be my favourite part of the paper. Here, Dr. Helbing shares his own views with us on the currently existing "soft"-AIs.  
In order to determine the true intelligence quality of AIs he considers whether they are autonomous, capable of emotion, capable of creativity, and conscious.  
This reminds me, yet again, to Turing's paper, who also tried to determine whether a computer could be capable of writing a sonnet. Dr. Helbing thinks that AI's are not autonomous, because they require human maintenance and external resources (also) provided by humans; thinks that AI systems are not capapble of emotion, due to the fact that mimicking emotion is not the same as actually feeling an emotion; and to the question whether he thinks that AI systems are conscious he answers simply: I would say "no", by argueing that we do not yet understand consciousness at all.  
At the end of this section the author notes that attemping to create humanoid robots might teach us a lesson or two about what love or consciousness is--then how are we supposed to create what we do not yet understand.  
I will dare to add a personal note here. I do not yet understand the current neuroscience literature at all. In my bookshelf at home sits a book on consciousness and I haven't touched the bloody thing yet. I know about as much about love, but I liked Brené Brown's definition of it. In case you are interested in reading a definition of love, look on her website on [https://brenebrown.com/definitions/](https://brenebrown.com/definitions/).

## What is consciousness
This part discusses the conjecture that world is an interpretation of higher-dimensional data. Furthermore the world was not limited to three dimension, but it is us who can only perceive it that way. Then as the author notes, the permanent distractions by the attention economy would just be the opposite of what would be needed to advance humanity.  
To make this more plausible the following example is given: consider why Egyptian and ancient paintings look flat, i.e. two-dimensional. Did ancient people see the world with _literally_ different eyes? This is interesting to think about, however I think it is too simplistic and narrow minded in it's analysis.

## Big Data Analytics
Chris Anderson claimed in an article in "Wired" magazine in 2008 that the scientific method would soon be obsolete due to Big Data Analysis. Simplified, that if one had just enough data, data quntity could be turned into data quality and thus the truth would eventually reveal itself.  
However, so far it seems to be harder than perhabs anticipated to harvest meaningful data. This seems to stem in part from false positives.

## Correlation vs. Causality
In Big Data patterns and correlations are easily found. However, one can not make any conclusions from said correlations. The following example is given: consider the correlation between the number of ice-cream-eating children and the number of forest fires. Forbidding children to eat ice cream will obviously not reduce the number of forest fires at all--despite the strong correlation in the data. It is obviously a third factor that causes both increased ince cream consumption and forest fires!

## Trustable AI
Ideally we could use AI to make sense of Big Data for us. However, according to Dr. Helbing AI's can only do this partly due to the fact that they show bias against women, non-white people, or minorities--this happens because they are usually trained with data of the past. Additionally, an AI can not explain it's own action, which could lead to a sitation where e.g. your application for a loan or life insurance is turned down, but nobody can tell you why.

## Profiling, Targeting, and Digital Twins
Thanks to the Edward Snowden leaks, we know that (at least) the American intelligence services have been running mass surveillance programs under the guise of fighting terrorism. Doing this, they created "profiles" of everyone. Dr. Elbing says "You may imagine this like a black box that has been crated for everyone, which is continuously fed with surveillance data and learns to behave like the humans they are imitating." Such systems can be used to personalize information and finally manipulate our behaviour in the way (most desirable) to the highest bidder.  
This reminds me of the Cambridge Analytic facebook manipulation case that is well documented in the Netflix documentation [The Great Hack](https://www.netflix.com/Title/80117542).

## Data Protection?
The EU General Data Protection Regulation (GDPR) should have protected us from mass surveillance, profiling and targeting in theory. But it did not, as the Snowden files showed. It seems almost impossible to use the internet without agreeing to Terms of Use beforehand, those contracts typically forces one into agreeing to the collection of ones personal data.  
The author additionally notes that we cannot even assume those personal profiles to be reliable (to be accurate). He notes the chances digital twins behave identical to us are not very high.

## Scoring, Citizen Scores, Superscores
Scoring is simillar to building a profile for people based on their personal data; however, it also assigns a value to peoples attributes, and data that eventually leads to a numerical value the score. Said value heavily inflicts one's life as it determines products availabe for them or more generally how one is treated. China is currently testing this approach under the name "Social Credit Score". According to the author the program may be seen as an attempt to make citizens obedient to the government's wishes, which has been critized as data dictatorship or technological totalitarianism.

## Automation vs. Freedom
In the age of AI it is tempting to automate processes of all kinds, including decision making. The latter often involes (either explicitly or implicitly) evaluating based on an index or a one-dimensional descision function. It is tempting to decide in a statistical manner. However the author heavily argues against this, for it effectively eliminates free choice. Alternatively, he proposes a semi-automated approach that reduces the decisions humans have to make by deciding the sure cases, while leaving the complex cases for the humans to process.

## Learning to Die?


## A revolution from above?

## Human Rights
According to the author human rights were established, due to the horrors of the twentiest century. He then goes on to say that the establishment of human rights is axiomatic for the foundation of modern civilizatin, which in turn is reflected by the UN's Universal Declaration of Human Rights--to prevent such catastrophies from happening again in the future.

As a student of Jordan Peterson and Alexandr Solzhenitsyn I could hardly disagree more. Firstly, I think it as wrong to proclaim that pre WW people had no human right. Can not the American constitution (as just one of many exmaples) be seen as proof for such a thing? Secondly, I believe that the burden to prevent a second 20th century is to solve at an individual level, and not by the UN or personal rights!  
However, in the next sentence Dr. Helbing argues that the promoting of a materialistic consumption-driven society has led the the current (non-) sustainability crisis. With this I can partly agree.

In the last paragraph the author points out that we would be living in a self sustaining world had the industrialized countries managed to reduce their resource consumption by 3% annually since the 1970s. I don't really know what to make of this, since I don't know any of the related literature.

## Happiness vs. Capitalism
Dr. Helbing argues that autonomy and good relationships are the best indicators for promoting personal happiness. He then goes saying, "I believe, if our soceity would be designed and managed in a way that supports the happiness of people, it would also be more sustainable, because happy people do not consume that much." I do not agree with this hypothesis or believe it at least to be overly simplistic. How can we know that happy people consume less?

However in the next paragraph the author points out that tech companies are partly to blame for the problems we are facing today. By their utilitarian practice of making users pay with their personal data and then selling that data to other companies, they might be seriously violating what we perceive as our right to privacy.

## Human Dignity
According to Dr. Helbing human dignity is given to us at birth and is axiomatic to societal values. The right to be treated as human towers above everything else. Politics and other institutions must do what they can, in order to proect human dignity from violations by public institutions etc. By not engaging in this practice public institutions lose their legitimacy.

But what is human dignity? The author says that it means to be treated differently from objects and animals, but as human--this is yet again (also) mentioned in Turing's paper on AI, where he explains that animals do not possess a soul in Christianity. It means to have the right to be involved in decisions and affaris that concern them, including the right of informational self-determination. Exposing people to unwanted mass surveillance is a clear violation of that.  
At the end of the section Dr. Helbing proclaims: "I do, therefore, urge public and private actors to push informational self-determination forward quickly."

## Informational Self-Determination
I had to look up what is meant with informational self-determination. According to the Wikipedia article it is derived from the German word "informationelle Selbstbestimmung" and stands for the right for one to decide for himself what of his data should be communicated with others and what should be kept private.

Dr. Helbing proposes a platform that would allow individuals to control which private data they allow a service to collect--and therefore allow them to use for e.g. personalized content, for which period of time, and perhabs for whichprice. The resulting competition for consumer trust could eventually promote a trustable digital society.

According to the author this platform would create a level playing field, for not only big businesses but also small organizations could work with the data (access approved by the people).

In Dr. Helbing's own words in the last paragraph in this section: "Over time, if implemented well, such an approach would establish a thriving trustable digital age that empowers people, companies and governments alike, while making quick progress towards a sustainable and peaceful world.

## Design for Values

## Democracy by Design
The author notes that among the social engineers of the digital age democracy has often been framed as outdated technology. 

The author then names "human dignity and human rights, (informational) self-determination, freedom (combined with accountability), pluralism, protection of minorities, division of power, checks and balances, participation, transparency, fairness, justice, legitimacy, anonymous and equal votes, and privacy" as relevant values for democracy.

## Fairness
The final topic on this paper is a discussion of the power of fairness: whether it is a good idea that everyone has a single vote. Contrary to European democratic values, shouldn't smart people have more than one vote? According to the author experimental evidence about the "wisdom of crowds" surprisingly suggests, giving people different weights does not improve results. "On the contrary, studies in collective intelligence show that largely unequal influence on a debate will reduce social intelligence", Dr. Helbing points out.